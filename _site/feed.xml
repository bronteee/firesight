<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-02-13T17:01:46-08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">FireSight - AI Insight on Wildfire Impact</title><subtitle>DREAM 2023 | Wildfire Spread Prediction in North America Using Satellite Imagery and Vision Transformer</subtitle><entry><title type="html">Week 8 | Exploring Different Deep Network Architectures</title><link href="http://localhost:4000/week8/" rel="alternate" type="text/html" title="Week 8 | Exploring Different Deep Network Architectures" /><published>2023-11-05T00:00:00-07:00</published><updated>2023-11-05T00:00:00-07:00</updated><id>http://localhost:4000/week8</id><content type="html" xml:base="http://localhost:4000/week8/">&lt;p&gt;In the past few weeks, we have experimented with different ways to improve the performance of our Unet model. We have tried different loss functions, different optimizers, and different input features. We have also explored the potential of using attention based Unet and residual connections. 
Now that we have gathered plenty of information on predicting wildfire spread with Unet, it is time to start exploring other deep learning architectures for this problem.
From looking at the current benchmarks for semantic segmentation, we have identified a few potential architectures that we can explore for this problem.&lt;/p&gt;

&lt;h2 id=&quot;swin-unet&quot;&gt;Swin-Unet&lt;/h2&gt;

&lt;p&gt;Swin-Unet[1] is a semantic segmentation model that combines the Swin Transformer with Unet. The Swin Transformer is a transformer based encoder-decoder proposed for medical image segmentation, which has been shown to outperform many other convolution based or hybrid models. This network uses shifted window to adapt Transformer to vision tasks and allows for efficient computation of self-attention within non-overlapping local windows. With the symmetric structure of Swin Transformer, the model can be easily adapted to our problem of modeling the spread of wildfires at t+1. We plan on using the implementation available &lt;a href=&quot;https://github.com/HuCaoFighting/Swin-Unet/tree/main&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;beit2&quot;&gt;BEiT2&lt;/h2&gt;

&lt;p&gt;Another potentially promising network to use is the BEiT2 v2 models that is currently the state-of-the-art in semantic segmentation for ADE2K. The BEiT2 model[3] is a transformer based architecture that leverages semantic rich visual tokenizer that can enhance global semantic representation on images. The idea here is we could utilize the pre-trained models available and attempt to fine-tune the model for wildfire spread prediction.&lt;/p&gt;

&lt;h2 id=&quot;diffusion-based-generative-approach&quot;&gt;Diffusion Based Generative Approach&lt;/h2&gt;

&lt;p&gt;Diffusion models have shown a lot of promise in the past few years especially in SOTA performance on image generation and constructing multi-modal distributions. With this, there are also recent developments in using diffusion for autoencoders as generation is believed to facilitate learning of latent representations and therefore enhance true understanding of image data. We are interested in exploring the potential of using diffusion based generative models for wildfire spread prediction. We hope to start with this paper[2] and assess the feasibility of using this approach for our problem, due to the intuition that the spread of wildfire is a generative process.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Wei, C., Mangalam, K., Huang, P.(., Li, Y., Fan, H., Xu, H., Wang, H., Xie, C., Yuille, A.L., &amp;amp; Feichtenhofer, C. (2023). Diffusion Models as Masked Autoencoders. ArXiv, abs/2304.03283.&lt;/li&gt;
  &lt;li&gt;Cao, H., Wang, Y., Chen, J., Jiang, D., Zhang, X., Tian, Q., &amp;amp; Wang, M. (2021). Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation. ECCV Workshops.&lt;/li&gt;
  &lt;li&gt;Bao, H., Dong, L., &amp;amp; Wei, F. (2021). BEiT: BERT Pre-Training of Image Transformers. ArXiv, abs/2106.08254.&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><category term="Wildfire" /><category term="Deep Learning" /><category term="machine learning" /><category term="AI" /><category term="UNet" /><category term="Transformer" /><category term="Segmentation" /><summary type="html">In the past few weeks, we have experimented with different ways to improve the performance of our Unet model. We have tried different loss functions, different optimizers, and different input features. We have also explored the potential of using attention based Unet and residual connections. Now that we have gathered plenty of information on predicting wildfire spread with Unet, it is time to start exploring other deep learning architectures for this problem. From looking at the current benchmarks for semantic segmentation, we have identified a few potential architectures that we can explore for this problem.</summary></entry><entry><title type="html">Week 7 | What We Have Found So Far</title><link href="http://localhost:4000/week7/" rel="alternate" type="text/html" title="Week 7 | What We Have Found So Far" /><published>2023-10-29T00:00:00-07:00</published><updated>2023-10-29T00:00:00-07:00</updated><id>http://localhost:4000/week7</id><content type="html" xml:base="http://localhost:4000/week7/">&lt;h2 id=&quot;useful-findings-and-insights-so-far&quot;&gt;Useful Findings and Insights So Far&lt;/h2&gt;

&lt;p&gt;After another week of exploring different ways to improve the performance of our model, we have found some useful insights and findings.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;So far, we have been able to achieve a PR-AUC of 0.31 by using UNet with 5 input features: precipitation, specific humidity, wind direction, NDVI, elevation, and previous day fire mask.&lt;/li&gt;
  &lt;li&gt;While the models are able to converge very fast with RMSprop optimizer, we achieve better overall validation and test results with ADAM on all models. However, ADAM takes up more memory which may be a limiting factor in our training.&lt;/li&gt;
  &lt;li&gt;Interestingly, by resetting the learning rate and optimizer every 6-7 epochs, we were able to continuously improve the validation dice and AUC scores with more epochs trained.&lt;/li&gt;
  &lt;li&gt;Despite the demonstrated advantages in using Focal Tversky loss function in studies performing similar prediction on wildfire spread[1], we implemented this loss function and conducted experiments, but found limited success in training with it - further investigation may be required.&lt;/li&gt;
  &lt;li&gt;Due to the size of Unet, CUDA out of memory errors are still a challenge given limited computing resources.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;other-improvements&quot;&gt;Other Improvements&lt;/h2&gt;
&lt;p&gt;While in the search for optimal parameters including batch size, optimizer to use, number of features, and loss function, we have also made continuous improvements on the project source library:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Better logging: additional logging on useful parameters on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wandb&lt;/code&gt; to allow for easier comparisons&lt;/li&gt;
  &lt;li&gt;Improved CUDA memory knowledge: conducted additional research on different ways to resolve CUDA out of memory errors and memory optimization with lower precision, offloading tensors from GPU, etc.&lt;/li&gt;
  &lt;li&gt;Improvements to allow for easier hyperparameter tuning and continued training by customizing training functions and checkpoint-ing&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;thinking-about-performance-in-terms-of-utility-and-human-centered-ai&quot;&gt;Thinking About Performance in Terms of Utility and Human Centered AI&lt;/h2&gt;

&lt;p&gt;Taking inspiration from the &lt;a href=&quot;https://blog.google/outreach-initiatives/sustainability/flood-hub-ai-flood-forecasting-more-countries/&quot;&gt;flood forecasting tool set from Google&lt;/a&gt;, we are thinking about how to evaluate the performance of our model in terms of utility. In the case of the flood forecasting tool set, the utility is defined as the number of people that are able to take action to protect themselves and their property. In our case, we are thinking about how to optimize our model in terms of the number of lives and properties that can benefit from the spread forecasting and what would be the most useful parameters to optimize for. We want to think about 1.the live public datasets available that can be used to perform real-time inference, 2. minimizing false negatives in the predictions, and 3. distance from fire. We will continue to explore this idea and think about how to better formulate the problem under the context of utility.&lt;/p&gt;

&lt;p&gt;Looking ahead, we will continue to explore the potential of the UNet architecture by adding more layers or width, though it is worth mentioning that computational resources are limited and we will need to be careful given the large dataset size and the significant increase in the number of parameters in the model. We will also continue to explore other more advanced networks including attention UNet with residual connections as well as the potential of using other attention based architectures such as vision transformers. In the meantime, it may worth considering the real-world application of this model in context of developing a wildfire prediction tool for predicting the spread of wildfires in real-time using Google earth data, for example, using live wildfire boundary maps described in this blog[2].&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Zou, Yufei et al. “Attention-Based Wildland Fire Spread Modeling Using Fire-Tracking Satellite Observations.” Fire (2023): n. pag.&lt;/li&gt;
  &lt;li&gt;https://blog.research.google/2023/02/real-time-tracking-of-wildfire.html&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Photo by &lt;a href=&quot;https://unsplash.com/@zekedrone?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Martin Sanchez&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/a-close-up-of-some-ice-LkN0Voym3Go?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Unsplash&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="Wildfire" /><category term="Deep Learning" /><category term="machine learning" /><category term="AI" /><category term="UNet" /><category term="Segmentation" /><summary type="html">Useful Findings and Insights So Far</summary></entry><entry><title type="html">Week 6 | Exploring Different Ways to Improve</title><link href="http://localhost:4000/week6/" rel="alternate" type="text/html" title="Week 6 | Exploring Different Ways to Improve" /><published>2023-10-22T00:00:00-07:00</published><updated>2023-10-22T00:00:00-07:00</updated><id>http://localhost:4000/week6</id><content type="html" xml:base="http://localhost:4000/week6/">&lt;p&gt;This week, we continue to look for ways to improve the performance of our model, by adding additional features and using Unet with attention. We also discuss another loss function that we will try.&lt;/p&gt;

&lt;h2 id=&quot;adding-additional-features&quot;&gt;Adding Additional Features&lt;/h2&gt;

&lt;p&gt;While we were able to achieve higher PR-AUC than the current benchmark using only 3 out of the 12 input features, we continued to explore the potential of the UNet architecture by adding more features. Therefore, we retrained the UNet model and added humidity(sph) and precipitation as input features. As a result, we were able to improve the PR-AUC score to 0.31 after training for only 5 epochs, which is already a significant improvement from the previous PR-AUC score of 0.293. Given this promising result, we will continue to explore the potential of the UNet architecture by adding more features, though it is worth mentioning that computational resources are limited and we will need to be careful about the number of features added, given the large dataset size and the significant increase in the number of parameters in the model.&lt;/p&gt;

&lt;h2 id=&quot;unet-with-attention&quot;&gt;UNet with Attention&lt;/h2&gt;

&lt;p&gt;Attention UNet[1] was first introduced to be able to focus on the pancreas in CT scans. The authors of the paper proposed a new architecture that combines the UNet architecture with attention gates. The attention gate is a mechanism that allows the model to focus on the most relevant features in the input. The attention gate is a 2D tensor of the same size as the input, and it is multiplied with the input to produce the output. The attention coefficients identify salient image regions and prune input features to preserve only activations relevant to the specific tasks. As a result, the attention gate is able to filter the input and focus on the most relevant features, which is useful for our problem of predicting next day wildfire, as the fire pixels are very sparse in the image and we want to apply more weight to the previous day fire mask.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/week6_att_unet.png&quot; alt=&quot;Attention Unet&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Furthermore, we would like to continue exploring other more advanced networks including recurrent attention UNet and attention UNet with residual connections. We will also explore the potential of using other attention mechanisms such as self-attention and non-local attention, as well as vision transformers.&lt;/p&gt;

&lt;h2 id=&quot;focal-loss-and-tversky-focal-loss&quot;&gt;Focal Loss and Tversky Focal Loss&lt;/h2&gt;

&lt;p&gt;Focal loss[2] is a loss function that is used to address the problem of class imbalance. The loss function is a modification of the cross entropy loss function, where the loss is weighted by a factor that is inversely proportional to the class frequency. The loss function is defined as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/week6_focal_loss.png&quot; alt=&quot;Focal Loss&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This loss function adds an additional focusing factor, gamma that allows for more weight to be applied to the hard examples. This is useful for our problem and worth a try, as the fire pixels are very sparse in the image, and we want to apply more weight to the fire pixels. Additionally, in [2] the authors proposed a new loss function called Tversky focal loss, which is a modification of the focal loss function, which uses the Tversky index, a generalization of the Dice score to allow for flexibility in balancing false positives and false negatives:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/week6_tversky_index.png&quot; alt=&quot;Tversky Index&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then the Tversky focal loss is defined as:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/week6_tversky_focal_loss.png&quot; alt=&quot;Tversky Focal Loss&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Due to the presence of many small ROI in our training samples, we will experiment with using this loss function similar to the study in [3] which also predicts the spread of wildfires using a different dataset.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Oktay, Ozan et al. “Attention U-Net: Learning Where to Look for the Pancreas.” ArXiv abs/1804.03999 (2018): n. pag.&lt;/li&gt;
  &lt;li&gt;Abraham, Nabila and Naimul Mefraz Khan. “A Novel Focal Tversky Loss Function With Improved Attention U-Net for Lesion Segmentation.” 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019) (2018): 683-687.&lt;/li&gt;
  &lt;li&gt;Zou Y, Sadeghi M, Liu Y, Puchko A, Le S, Chen Y, Andela N, Gentine P. Attention-Based Wildland Fire Spread Modeling Using Fire-Tracking Satellite Observations. Fire. 2023; 6(8):289. https://doi.org/10.3390/fire6080289&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Photo by &lt;a href=&quot;https://unsplash.com/@heytowner?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;JOHN TOWNER&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/empty-concrete-road-covered-surrounded-by-tall-tress-with-sun-rays-3Kv48NS4WUU?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Unsplash&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="Wildfire" /><category term="Deep Learning" /><category term="machine learning" /><category term="AI" /><category term="UNet" /><category term="Segmentation" /><summary type="html">This week, we continue to look for ways to improve the performance of our model, by adding additional features and using Unet with attention. We also discuss another loss function that we will try.</summary></entry><entry><title type="html">Week 5 | New Baseline Results</title><link href="http://localhost:4000/week5/" rel="alternate" type="text/html" title="Week 5 | New Baseline Results" /><published>2023-10-14T00:00:00-07:00</published><updated>2023-10-14T00:00:00-07:00</updated><id>http://localhost:4000/week5</id><content type="html" xml:base="http://localhost:4000/week5/">&lt;p&gt;With the results from last week, it was clear that we were not approaching the problem correctly. For example, through examining the fire mask prediction results from the trained UNet model, we discovered that by using a loss function that was a combination of binary cross entropy and dice loss, the model was not able to predict the fire masks correctly - in fact, the model was not predicting any positive fire pixels at all. This week, we will present results from training the model using only the weighted binary cross entropy loss function.&lt;/p&gt;

&lt;h2 id=&quot;identifying-the-issue&quot;&gt;Identifying the Issue&lt;/h2&gt;

&lt;p&gt;From the previous week, we saw that the model was not predicting any positive fire pixels. Through some investigation, we hypothesized that this could be due to the loss function being not appropriate for this particular problem. To test this hypothesis, we decided to train the model using only the weighted binary cross entropy loss function, and use the same metrics as the original paper to evaluate the model so that we have a better reference point.&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;p&gt;The training results for Unet and the model details are as follows:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Checkpoint/Description&lt;/th&gt;
      &lt;th&gt;Dice Score&lt;/th&gt;
      &lt;th&gt;PR AUC&lt;/th&gt;
      &lt;th&gt;Precision&lt;/th&gt;
      &lt;th&gt;Recall&lt;/th&gt;
      &lt;th&gt;Weighted F1&lt;/th&gt;
      &lt;th&gt;Benchmark PR AUC&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Epoch 7, BCE loss with pos_weight=3, pos threshold 0.6&lt;/td&gt;
      &lt;td&gt;0.33&lt;/td&gt;
      &lt;td&gt;0.293&lt;/td&gt;
      &lt;td&gt;0.41&lt;/td&gt;
      &lt;td&gt;0.22&lt;/td&gt;
      &lt;td&gt;0.28&lt;/td&gt;
      &lt;td&gt;0.284&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Epoch 7, BCE loss with pos_weight=3, pos threshold 0.5&lt;/td&gt;
      &lt;td&gt;0.31&lt;/td&gt;
      &lt;td&gt;0.293&lt;/td&gt;
      &lt;td&gt;0.34&lt;/td&gt;
      &lt;td&gt;0.37&lt;/td&gt;
      &lt;td&gt;0.34&lt;/td&gt;
      &lt;td&gt;0.284&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Epoch 7, BCE loss with pos_weight=3, pos threshold 0.4&lt;/td&gt;
      &lt;td&gt;0.29&lt;/td&gt;
      &lt;td&gt;0.293&lt;/td&gt;
      &lt;td&gt;0.28&lt;/td&gt;
      &lt;td&gt;0.50&lt;/td&gt;
      &lt;td&gt;0.35&lt;/td&gt;
      &lt;td&gt;0.284&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Epoch 3, BCE loss with pos_weight=100, pos threshold 0.5&lt;/td&gt;
      &lt;td&gt;0.17&lt;/td&gt;
      &lt;td&gt;0.20&lt;/td&gt;
      &lt;td&gt;0.11&lt;/td&gt;
      &lt;td&gt;0.79&lt;/td&gt;
      &lt;td&gt;0.19&lt;/td&gt;
      &lt;td&gt;0.284&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that by using a more appropriate loss function, not only were we able to predict positive fire pixels, but we were also able to achieve a PR AUC score of 0.293, which is slightly higher than the benchmark PR AUC score of 0.284.&lt;/p&gt;

&lt;p&gt;Some example predictions:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Predicted Fire Mask&lt;/th&gt;
      &lt;th&gt;True Fire Mask&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;/images/week5_results/14_pred.png&quot; alt=&quot;14_prediction&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;/images/week5_results/14_true.png&quot; alt=&quot;14_true&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;/images/week5_results/15_pred.png&quot; alt=&quot;15_prediction&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;/images/week5_results/15_true.png&quot; alt=&quot;15_true&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;/images/week5_results/29_pred.png&quot; alt=&quot;29_prediction&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;/images/week5_results/29_true.png&quot; alt=&quot;29_true&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;/images/week5_results/114_pred.png&quot; alt=&quot;114_prediction&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;/images/week5_results/114_true.png&quot; alt=&quot;114_true&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s Next&lt;/h2&gt;

&lt;p&gt;This is exciting progress as we were able to get a higher PR-AUC than the original methods in the &lt;a href=&quot;https://arxiv.org/abs/2112.02447&quot;&gt;Next Day Wildfire paper&lt;/a&gt;. To further improve the results and extract additional potential from the UNet architecture, we will try the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Add batch norm or layer norm&lt;/li&gt;
  &lt;li&gt;Add more features as input&lt;/li&gt;
  &lt;li&gt;Try different loss functions&lt;/li&gt;
  &lt;li&gt;Increase width of Unet by increasing number of kernels in each block&lt;/li&gt;
  &lt;li&gt;Increase depth of Unet by adding more pairs of encoder/decoder blocks&lt;/li&gt;
  &lt;li&gt;Try augmenting the Unet with &lt;a href=&quot;https://github.com/sheikhazhanmohammed/sadma&quot;&gt;this paper&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Try different architectures&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Photo by &lt;a href=&quot;https://unsplash.com/@pavement_special?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Riccardo Annandale&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/7e2pe9wjL9M?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Unsplash&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="Wildfire" /><category term="Deep Learning" /><category term="machine learning" /><category term="AI" /><summary type="html">With the results from last week, it was clear that we were not approaching the problem correctly. For example, through examining the fire mask prediction results from the trained UNet model, we discovered that by using a loss function that was a combination of binary cross entropy and dice loss, the model was not able to predict the fire masks correctly - in fact, the model was not predicting any positive fire pixels at all. This week, we will present results from training the model using only the weighted binary cross entropy loss function.</summary></entry><entry><title type="html">Week 4 | Metrics and Loss Functions</title><link href="http://localhost:4000/week4/" rel="alternate" type="text/html" title="Week 4 | Metrics and Loss Functions" /><published>2023-10-02T00:00:00-07:00</published><updated>2023-10-02T00:00:00-07:00</updated><id>http://localhost:4000/week4</id><content type="html" xml:base="http://localhost:4000/week4/">&lt;p&gt;With the results from last week, it was clear that we were not approaching the problem correctly. For example, through examining the fire mask prediction results from the trained UNet model, we discovered that by using a loss function that was a combination of binary cross entropy and dice loss, the model was not able to predict the fire masks correctly - in fact, the model was not predicting any positive fire pixels at all. This week, we will dig further into the losses and metrics used by the original next day wild fire paper and train our model using the same losses and metrics on the dataset.&lt;/p&gt;

&lt;h2 id=&quot;challenges-of-the-problem&quot;&gt;Challenges of the Problem&lt;/h2&gt;

&lt;p&gt;Looking at the problem of predicting next day wildfire again, it is clear that this is not a typical segmentation problem. The main challenge of this problem is that the fire pixels are very sparse in the image. In fact, the fire pixels only make up about 1% of the image. This means that the model will be trained on a dataset that is very imbalanced. This is a problem because the model will be trained to predict the majority class (non-fire pixels) and will not be able to predict the minority class (fire pixels) well.&lt;/p&gt;

&lt;h2 id=&quot;weighted-binary-cross-entropy&quot;&gt;Weighted Binary Cross Entropy&lt;/h2&gt;

&lt;p&gt;Cross entropy is a loss function that is used to measure the performance of a classification model whose output is a probability value between 0 and 1. The loss function is commonly used in machine learning and deep learning models, as the following:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/cross_entropy.webp&quot; alt=&quot;Cross Entropy&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After applying an activation function of either sigmoid or softmax, for each class in the output, the cross entropy loss is calculated. The loss is then summed up for all classes and averaged over all samples. The loss function is then minimized by the model during training.&lt;/p&gt;

&lt;p&gt;For our problem of predicting next day fire, we can think of using binary cross entropy to classify at each location on the map the probability of a fire. However, because we have a serious imbalance between the number of positive and negative samples, we need to weight the loss function to account for this imbalance. We can do this by assigning a weight to each class. The weight for the positive class is the inverse of the proportion of positive samples in the dataset, and the weight for the negative class is the inverse of the proportion of negative samples in the dataset. This way, the loss function will be weighted more towards the positive class, and the model will be trained to predict the positive class better. This means that for the next round of experiments, we will be using a weighted binary cross entropy as our only loss function to train our model.&lt;/p&gt;

&lt;h2 id=&quot;auc-precision-and-recall&quot;&gt;AUC, Precision and Recall&lt;/h2&gt;

&lt;p&gt;In addition to the weighted binary cross entropy loss function, we will also be using the AUC, precision and recall metrics to evaluate our model. The AUC metric is the area under the ROC curve, which is a plot of the true positive rate (TPR) against the false positive rate (FPR). The TPR is the proportion of positive samples that are correctly identified as positive, and the FPR is the proportion of negative samples that are incorrectly identified as positive.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/metrics.jpg&quot; alt=&quot;Metrics&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/roc_curve.svg&quot; alt=&quot;ROC Curve&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;For more information on the ROC curve, see &lt;a href=&quot;https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S016786550500303X#sec4&quot;&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Photo by &lt;a href=&quot;https://unsplash.com/@lazycreekimages?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Michael Dziedzic&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/photos/dSyhpTGhNHg?utm_content=creditCopyText&amp;amp;utm_medium=referral&amp;amp;utm_source=unsplash&quot;&gt;Unsplash&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="Wildfire" /><category term="Deep Learning" /><category term="machine learning" /><category term="AI" /><summary type="html">With the results from last week, it was clear that we were not approaching the problem correctly. For example, through examining the fire mask prediction results from the trained UNet model, we discovered that by using a loss function that was a combination of binary cross entropy and dice loss, the model was not able to predict the fire masks correctly - in fact, the model was not predicting any positive fire pixels at all. This week, we will dig further into the losses and metrics used by the original next day wild fire paper and train our model using the same losses and metrics on the dataset.</summary></entry><entry><title type="html">Week 3 | Unet and Baseline Results</title><link href="http://localhost:4000/week3/" rel="alternate" type="text/html" title="Week 3 | Unet and Baseline Results" /><published>2023-09-25T00:00:00-07:00</published><updated>2023-09-25T00:00:00-07:00</updated><id>http://localhost:4000/week3</id><content type="html" xml:base="http://localhost:4000/week3/">&lt;p&gt;Now that we have our dataset ready, it is time to obtain some baseline results with the goal of 1/ evaluate the difficulty of the problem and 2/ determine if the problem is framed correctly. With that in mind, we will be using the Unet architecture as the starting architecture for this segmentation task.&lt;/p&gt;

&lt;h2 id=&quot;framing-of-the-problem&quot;&gt;Framing of the Problem&lt;/h2&gt;

&lt;p&gt;Before we get into the solution, let’s take a step back and look at the problem we are trying to solve in the context of deep learning. As we saw last week, we are given a 3D tensor of shape (12, 64, 64) as input, and we are trying to predict a 2D tensor of shape (64, 64) as output, which is our next day fire mask. We can think of this as a segmentation problem, where the task is classification of each output pixel as either 0 or 1, where 0 means no fire and 1 means fire. So how do we know how good the prediction is? Two common metrics for segmentation tasks are the &lt;a href=&quot;https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient&quot;&gt;Dice coefficient&lt;/a&gt; and the &lt;a href=&quot;https://en.wikipedia.org/wiki/Jaccard_index&quot;&gt;Jaccard index&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Given two sets X and Y, Dice coefficient is defined as:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dice_coefficient.png&quot; alt=&quot;dice_coefficient&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Whereas similarly, the Jaccard index is defined as:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/jaccard_index.png&quot; alt=&quot;jaccard_index&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the context of our fire spread prediction, we can think of the ground truth fire mask as a set of pixels A and the predicted fire mask as a set of pixels B. Then, the Dice coefficient and Jaccard index can be used to evaluate the accuracy of the prediction. The higher the value, the better the prediction.&lt;/p&gt;

&lt;h2 id=&quot;unet&quot;&gt;Unet&lt;/h2&gt;

&lt;p&gt;Unet is a simple yet powerful architecture originally developed for biomedical imaging segmentation tasks. It is composed of an encoder and a decoder, where the encoder is a series of convolutional layers that downsample the input, and the decoder is a series of convolutional layers that upsample the input. The encoder and decoder are connected by skip connections, which allow the decoder to use information from the encoder to improve the segmentation results. The architecture is shown below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/u-net-architecture.png&quot; alt=&quot;unet_image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Using this network allows us to get some initial results relatively fast to get a handle on the problem of predicting wildfire spread, and if the results are promising, we can then explore more sophisticated architectures.&lt;/p&gt;

&lt;h2 id=&quot;baseline-results&quot;&gt;Baseline Results&lt;/h2&gt;

&lt;p&gt;Due to the large size of the dataset and limited GPU resources, we downsampled the dataset from 64x64 to 32x32 and only used the 3 most important dimensions discovered in the original dataset paper: previous day fire mask, vegetation, and elevation. For the loss function, we used binary cross entropy with a positive weight of 100 to account for the imbalance between fire and no fire pixels, and for the optimizer, we used the default Unet scheduler with a learning rate of 1e-5.&lt;/p&gt;

&lt;p&gt;The model was trained on an A800-80G GPU for 10 epochs, and we obtained the following results:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/train_loss_unet.png&quot; alt=&quot;train_loss_unet&quot; /&gt;
&lt;img src=&quot;/images/validation_unet.png&quot; alt=&quot;validation_unet&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As shown here in the results, we can see that unfortunately the dice score is plateauing at around 0.18, which is not very good. There are a few possible explanations, including the fact that the model is too simple, or the problem is not framed correctly. We will explore these possibilities in the next few weeks.&lt;/p&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;Next week, we will be exploring the possibility of:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Preprocessing in different ways the input and target labels to improve the results, for example, by using a different representation of the target labels including using the change in fire rather than fire/no fire. Another idea is to only predict the surrounding the current fire perimeter rather than the entire image, mentioned in the &lt;a href=&quot;https://www.ijcai.org/proceedings/2019/636&quot;&gt;FireCast paper&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Applying a different loss function that may better reflect the nature of the problem by reviewing and trying out implementations &lt;a href=&quot;https://github.com/shruti-jadon/Semantic-Segmentation-Loss-Functions&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Photo by &lt;a href=&quot;https://unsplash.com/@urielsc26&quot;&gt;Uriel SC&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com&quot;&gt;Unsplash&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="Wildfire" /><category term="Unet" /><category term="Deep Learning" /><category term="machine learning" /><category term="AI" /><summary type="html">Now that we have our dataset ready, it is time to obtain some baseline results with the goal of 1/ evaluate the difficulty of the problem and 2/ determine if the problem is framed correctly. With that in mind, we will be using the Unet architecture as the starting architecture for this segmentation task.</summary></entry><entry><title type="html">Week 2 | Finding the Right Dataset</title><link href="http://localhost:4000/week2/" rel="alternate" type="text/html" title="Week 2 | Finding the Right Dataset" /><published>2023-09-18T00:00:00-07:00</published><updated>2023-09-18T00:00:00-07:00</updated><id>http://localhost:4000/week2</id><content type="html" xml:base="http://localhost:4000/week2/">&lt;p&gt;This week, we will dive into the first step of the project: finding the right dataset. We will discuss the problem, potential solutions, and the dataset we will use for the project.&lt;/p&gt;

&lt;p&gt;For the first phase of the project, we focus on short-term predictions of wildfires. Concretely, this means that we will be predicting the spread of a wildfire, which is a critical task and a difficult problem where there can be many different approaches. However, solving this issue will contribute significantly to land management and fire disaster response efforts, providing useful insights for both emergency teams and individuals that may be in the vicinity of high risk areas.&lt;/p&gt;

&lt;h2 id=&quot;the-dataset-we-will-use&quot;&gt;The Dataset We Will Use&lt;/h2&gt;
&lt;p&gt;The next day wildfire dataset is a comprehensive compilation of wildfire data from the United States based on Google earth data from 2012 to 2020. It contains 2D information about 12 relevant variables including vegetation, elevation, weather, fire map at t day and fire mask at t+1 day. This dataset has the potential as a benchmark dataset for fire propagation prediction, while there have been few studies on this particular topic. The dataset is publicly available &lt;a href=&quot;https://www.kaggle.com/datasets/fantineh/next-day-wildfire-spread&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Looking closer at the dataset this week, we were able to identify the specific shapes of the input and output:&lt;/p&gt;

&lt;p&gt;The input is a 3D tensor of shape (12, 64, 64), where the first dimension represents the 12 variables relevant to fire spread, the second and third dimensions represent the 64x64 grid of the area of interest. The output is a 2D tensor of shape (64, 64), where each pixel represents the presence of fire at that location.&lt;/p&gt;

&lt;p&gt;The visualization below is an example of the input and output for a given day, more details are available from the paper that introduced the dataset &lt;a href=&quot;https://arxiv.org/abs/2112.02447&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/data_vis.png&quot; alt=&quot;Input and Output&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;augmenting-the-dataset&quot;&gt;Augmenting the Dataset&lt;/h2&gt;

&lt;p&gt;Due to the drastic increase in number and frequency of wildfires in the last few years, we decided to augment the next day wildfire dataset be expanding its time and location range. We will be using the same 12 variables as the original dataset, but we will be using data from 2012 to 2023, and we will be expanding the area of interest to the entire North America. This will allow us to train a model that can generalize to a more recent time period and a larger area, which will be more useful for real-world applications in the context of this project.&lt;/p&gt;

&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;/h2&gt;

&lt;p&gt;It is easy to see that the the prediction of the t+1 day fire mask can be framed as a segmentation problem, where the task is classification of each output pixel as either 0 or 1, where 0 means no fire and 1 means fire. However, the input is not a simple image, but a 3D tensor of shape (12, 64, 64). This means that we will need to find a way to transform the input into a 2D image, which we can then use to train a segmentation model.&lt;/p&gt;

&lt;h2 id=&quot;potential-solutions&quot;&gt;Potential Solutions&lt;/h2&gt;

&lt;p&gt;There are a number of potential solutions to this problem, and the original paper for this dataset explores a few of them, including employing both CNN based methods and LSTM based methods as well as using classical machine learning like random forests. While having results from these methods is useful, more sophisticated DNN architectures have not been used on this dataset, and we will start with a simple &lt;a href=&quot;https://arxiv.org/abs/1505.04597&quot;&gt;U-Net&lt;/a&gt; to get a baseline for our project.&lt;/p&gt;

&lt;p&gt;Photo by &lt;a href=&quot;https://unsplash.com/@nasa&quot;&gt;NASA&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/@nasa&quot;&gt;Unsplash&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="climate change" /><category term="machine learning" /><category term="AI" /><summary type="html">This week, we will dive into the first step of the project: finding the right dataset. We will discuss the problem, potential solutions, and the dataset we will use for the project.</summary></entry><entry><title type="html">Week 1 | What Can Machine Learning Do for Climate Change?</title><link href="http://localhost:4000/week1/" rel="alternate" type="text/html" title="Week 1 | What Can Machine Learning Do for Climate Change?" /><published>2023-09-11T00:00:00-07:00</published><updated>2023-09-11T00:00:00-07:00</updated><id>http://localhost:4000/week1</id><content type="html" xml:base="http://localhost:4000/week1/">&lt;p&gt;Climate change is one of the biggest challenges facing our world today. Rising global temperatures, shifting weather patterns, and more extreme weather events are already impacting communities worldwide. Machine learning, a type of artificial intelligence, offers new hope in the fight against climate change.&lt;/p&gt;

&lt;p&gt;Machine learning algorithms can analyze massive datasets quickly to uncover hidden insights. This makes them uniquely suited to tackling the complexity of climate science, incorporating many different factors in making better predictions for future changes. In the exploration of how machine learning can be applied to tackle a specific problem, there are three main questions to consider:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;What is the problem we want to solve / needs to be solved?&lt;/li&gt;
  &lt;li&gt;What is the data available / what kinds of data should be applied?&lt;/li&gt;
  &lt;li&gt;What is the solution?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;One way machine learning is being applied is in predicting and managing wildfires. Wildfires are increasing in frequency and severity due to hotter, drier conditions. Computer vision algorithms can analyze satellite imagery to identify areas at highest risk of wildfires. This allows fire officials to proactively allocate resources and better plan controlled burns. For example, we can estimate the spread of the fire in the short term, which helps authorities safely evacuate residents in the fire’s path. After fires, machine learning can help assess damage to man-made structures and environmental assets. This information guides recovery and restoration efforts. Machine learning can even identify ways to improve infrastructure design to be more resilient to future fires.&lt;/p&gt;

&lt;p&gt;My current project focuses on developing machine learning models for wildfire modeling here in North America.  By training algorithms on satellite imagery and data like vegetation, wind direction, etc., we hope to better understand wildfire behavior in the short term, and its impact on marginalized communities in the long term. This will arm officials with science-based, insights to help our community adapt to our hotter, drier future. Machine learning offers data-driven solutions to curb the impacts of climate change and help mitigate risks to the most vulnerable populations.&lt;/p&gt;

&lt;p&gt;Photo by &lt;a href=&quot;https://unsplash.com/@li_anlim&quot;&gt;Li-An Lim&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com&quot;&gt;Unsplash&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="climate change" /><category term="machine learning" /><category term="AI" /><summary type="html">Climate change is one of the biggest challenges facing our world today. Rising global temperatures, shifting weather patterns, and more extreme weather events are already impacting communities worldwide. Machine learning, a type of artificial intelligence, offers new hope in the fight against climate change.</summary></entry></feed>